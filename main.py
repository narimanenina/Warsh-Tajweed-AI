import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import librosa
import numpy as np
import re
from streamlit_mic_recorder import mic_recorder
from pydub import AudioSegment

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¨ØµØ±ÙŠØ© ---
st.set_page_config(page_title="Ù…ØµØ­Ø­ ØªÙ„Ø§ÙˆØ© ÙˆØ±Ø´ - Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ù‚", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { font-family: 'Amiri', serif; direction: rtl; text-align: right; }
    .quran-card {
        background-color: #f9fbf9; padding: 25px; border-radius: 15px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1); border-right: 8px solid #2E7D32;
        margin-bottom: 20px; color: #1B5E20;
    }
    .metric-box {
        background-color: white; padding: 15px; border-radius: 10px;
        border: 1px solid #c8e6c9; text-align: center;
    }
    .stButton>button { background-color: #2E7D32; color: white; border-radius: 10px; width: 100%; }
    h1 { color: #1B5E20; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©) ---
@st.cache_data
def load_phonetics():
    if os.path.exists('arabic_phonetics.csv'):
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ (letter, name, place, rule_category, emphasis, ipa)
        return pd.read_csv('arabic_phonetics.csv', encoding='utf-8-sig')
    return None

df_rules = load_phonetics()

# --- 3. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ---

def normalize_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹Ø§Ø¯Ù„Ø© (ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù‡Ù…Ø²Ø§Øª ÙˆØ§Ù„ØªØ´ÙƒÙŠÙ„)"""
    text = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", text)
    text = re.sub(r"[\u064B-\u0652]", "", text) 
    return text.strip()

def get_phonetic_info(word):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ Ù„ÙƒÙ„ Ø­Ø±Ù ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ù† Ù…Ù„Ù CSV"""
    info_list = []
    if df_rules is not None:
        for char in word:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø­Ø±Ù ÙÙŠ Ø¹Ù…ÙˆØ¯ letter
            match = df_rules[df_rules['letter'] == char]
            if not match.empty:
                row = match.iloc[0]
                info_list.append({
                    'Ø§Ù„Ø­Ø±Ù': row['letter'],
                    'Ø§Ù„Ø§Ø³Ù…': row['name'],
                    'Ø§Ù„Ù…Ø®Ø±Ø¬': row['place'],
                    'Ø§Ù„Ø­ÙƒÙ…': row['rule_category'],
                    'Ø§Ù„ØµÙØ©': row['emphasis']
                })
    return info_list

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title("ğŸ•Œ Ù…ØµØ­Ø­ ØªÙ„Ø§ÙˆØ© ÙˆØ±Ø´")
st.subheader("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

# Ø¹Ø±Ø¶ ØµÙˆØ± Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø±Ø¬Ø¹ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)


with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    target_text = st.text_area("Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", "Ø¥Ù†Ø§ Ø£Ø¹Ø·ÙŠÙ†Ø§Ùƒ Ø§Ù„ÙƒÙˆØ«Ø±")
    
    if df_rules is not None:
        with st.expander("ğŸ“„ Ø¹Ø±Ø¶ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø­ÙƒØ§Ù… (CSV)"):
            st.dataframe(df_rules)

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡
audio_data = mic_recorder(start_prompt="ğŸ”´ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ„Ø§ÙˆØ©", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù ÙˆØ§Ø·Ù„Ø¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„", key='warsh_v6')

if audio_data:
    audio_bytes = audio_data['bytes']
    
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ„Ø§ÙˆØ© ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ø§Ù„Ø£Ø­ÙƒØ§Ù…..."):
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©
            audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
            buf = io.BytesIO()
            audio.export(buf, format="wav")
            buf.seek(0)
            
            r = sr.Recognizer()
            with sr.AudioFile(buf) as source:
                audio_recorded = r.record(source)
                spoken_text = r.recognize_google(audio_recorded, language="ar-SA")
            
            # Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ©
            norm_target = normalize_text(target_text)
            norm_spoken = normalize_text(spoken_text)
            accuracy = round(difflib.SequenceMatcher(None, norm_target.split(), norm_spoken.split()).ratio() * 100, 1)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.markdown("<div class='quran-card'>", unsafe_allow_html=True)
            st.markdown(f"<h2 style='text-align:center;'>Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥ØªÙ‚Ø§Ù†: {accuracy}%</h2>", unsafe_allow_html=True)
            st.write(f"**Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªØ´Ù:** {spoken_text}")
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ Ù„Ù„ÙƒÙ„Ù…Ø§Øª
            st.divider()
            st.subheader("ğŸ“ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„Ù CSV):")
            
            words = target_text.split()
            for word in words:
                clean_word = re.sub(r"[\u064B-\u0652]", "", word)
                phonetics = get_phonetic_info(clean_word)
                
                with st.expander(f"ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø©: {word}"):
                    if phonetics:
                        # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø©
                        temp_df = pd.DataFrame(phonetics)
                        st.table(temp_df)
                    else:
                        st.write("Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù.")
            
            st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£: ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶ÙˆØ­ Ø§Ù„ØµÙˆØª. (Ø§Ù„ØªÙØ§ØµÙŠÙ„: {e})")
