import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import librosa
import numpy as np
import re
import soundfile as sf
from streamlit_mic_recorder import mic_recorder
from pydub import AudioSegment
from fastdtw import fastdtw
from scipy.spatial.distance import euclidean

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª ---
st.set_page_config(page_title="Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø°ÙƒÙŠØ© - Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©", layout="centered", page_icon="ğŸ•Œ")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { font-family: 'Amiri', serif; direction: rtl; text-align: right; }
    .st-emotion-cache-p4m61c { flex-direction: row-reverse !important; }
    .main-card {
        background-color: #fcfdfc; padding: 20px; border-radius: 15px;
        border-right: 10px solid #2E7D32; box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        margin-bottom: 20px;
    }
    .score-box { text-align:center; padding:15px; background-color:#e8f5e9; border-radius:12px; margin:10px 0; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø­ÙƒØ§Ù… (CSV) ---
@st.cache_data
def load_warsh_data():
    if os.path.exists('arabic_phonetics.csv'):
        return pd.read_csv('arabic_phonetics.csv', encoding='utf-8-sig')
    return None

df_rules = load_warsh_data()

# --- 3. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠ ---

def get_tajweed_feedback(word):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø­ÙƒØ§Ù… Ø§Ù„ØªØ¬ÙˆÙŠØ¯ Ù…Ù† Ù…Ù„Ù CSV Ù„ÙƒÙ„ Ø­Ø±Ù"""
    feedback = []
    if df_rules is not None:
        clean_word = re.sub(r"[\u064B-\u0652]", "", word)
        for char in clean_word:
            match = df_rules[df_rules['letter'] == char]
            if not match.empty:
                row = match.iloc[0]
                feedback.append({'Ø§Ù„Ø­Ø±Ù': row['letter'], 'Ø§Ù„Ù…Ø®Ø±Ø¬': row['place'], 'Ø§Ù„Ø­ÙƒÙ…': row['rule_category'], 'Ø§Ù„ØµÙØ©': row['emphasis']})
    return feedback

def calculate_voice_similarity(teacher_bytes, student_bytes):
    """Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØªÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø´ÙŠØ® ÙˆØ§Ù„ØªÙ„Ù…ÙŠØ° Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DTW"""
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„ØµÙŠØºØ© Ù…ØªÙˆØ§ÙÙ‚Ø© Ø¹Ø¨Ø± pydub
    t_audio = AudioSegment.from_file(io.BytesIO(teacher_bytes)).set_frame_rate(22050).set_channels(1)
    s_audio = AudioSegment.from_file(io.BytesIO(student_bytes)).set_frame_rate(22050).set_channels(1)
    
    y_t = np.array(t_audio.get_array_of_samples(), dtype=np.float32)
    y_s = np.array(s_audio.get_array_of_samples(), dtype=np.float32)

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù…ÙŠØ²Ø§Øª Ø±Ù†ÙŠÙ† Ø§Ù„Ø­Ø±ÙˆÙ (MFCCs)
    mfcc_t = librosa.feature.mfcc(y=y_t, sr=22050)
    mfcc_s = librosa.feature.mfcc(y=y_s, sr=22050)
    
    # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
    distance, _ = fastdtw(mfcc_t.T, mfcc_s.T, dist=euclidean)
    similarity = 100 / (1 + (distance / 50000)) 
    return round(similarity, 1)

def process_audio_for_stt(audio_bytes):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…"""
    audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
    wav_buf = io.BytesIO()
    audio.export(wav_buf, format="wav")
    wav_buf.seek(0)
    return wav_buf

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.markdown("<h1 style='text-align: center; color: #1B5E20;'>ğŸ•Œ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© ÙˆØªØµØ­ÙŠØ­ Ø§Ù„ØªÙ„Ø§ÙˆØ©</h1>", unsafe_allow_html=True)

with st.sidebar:
    st.header("ğŸ“– Ø¶Ø¨Ø· Ø§Ù„Ø¬Ù„Ø³Ø©")
    target_text = st.text_area("Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ù…Ø±Ø§Ø¯ Ø§Ù„ØªØ¯Ø±Ø¨ Ø¹Ù„ÙŠÙ‡Ø§:", "Ø¥Ù†Ø§ Ø£Ø¹Ø·ÙŠÙ†Ø§Ùƒ Ø§Ù„ÙƒÙˆØ«Ø±")
    st.divider()
    st.subheader("ğŸ‘¨â€ğŸ« Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹")
    teacher_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØª Ø§Ù„Ø´ÙŠØ® (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", type=['wav', 'mp3', 'ogg'])
    if teacher_file:
        st.audio(teacher_file)
        t_bytes = teacher_file.read()

# Ù…Ø³Ø§Ø­Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
st.markdown("<div class='main-card'>", unsafe_allow_html=True)
st.subheader("ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªÙ„Ù…ÙŠØ°")
student_rec = mic_recorder(start_prompt="Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ„Ø§ÙˆØ© / Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©", stop_prompt="ØªÙˆÙ‚Ù ÙˆØ§Ø¸Ù‡Ø± Ø§Ù„Ù†ØªÙŠØ¬Ø©", key='final_warsh_v15')
st.markdown("</div>", unsafe_allow_html=True)

if student_rec:
    s_bytes = student_rec['bytes']
    
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ ÙˆÙ…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡..."):
        try:
            # 1. Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù… (Ø§Ù„Ù…ØµØ­Ø­ Ø§Ù„Ø¢Ù„ÙŠ)
            wav_buffer = process_audio_for_stt(s_bytes)
            r = sr.Recognizer()
            with sr.AudioFile(wav_buffer) as source:
                audio_recorded = r.record(source)
                spoken_text = r.recognize_google(audio_recorded, language="ar-SA")
            
            # 2. Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù†Øµ
            norm_target = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", target_text)
            norm_spoken = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", spoken_text)
            text_acc = round(difflib.SequenceMatcher(None, norm_target.split(), norm_spoken.split()).ratio() * 100, 1)

            # 3. Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            st.markdown("<div class='main-card'>", unsafe_allow_html=True)
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"<div class='score-box'><h4>Ø¯Ù‚Ø© Ø§Ù„Ø£Ù„ÙØ§Ø¸</h4><h2>{text_acc}%</h2></div>", unsafe_allow_html=True)
            
            # Ø¥Ø°Ø§ Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØµÙˆØª Ø§Ù„Ø´ÙŠØ®ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø³Ù…Ø¹ÙŠØ©
            if teacher_file:
                voice_sim = calculate_voice_similarity(t_bytes, s_bytes)
                with col2:
                    st.markdown(f"<div class='score-box'><h4>Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø´ÙŠØ®</h4><h2>{voice_sim}%</h2></div>", unsafe_allow_html=True)
            
            st.write(f"**Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚:** {spoken_text}")
            
            # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ù…Ù† Ø§Ù„Ù€ CSV
            st.divider()
            st.markdown("### ğŸ“‹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¬ÙˆÙŠØ¯ÙŠ ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„ÙÙƒ):")
            words = target_text.split()
            for word in words:
                tajweed_data = get_tajweed_feedback(word)
                if tajweed_data:
                    with st.expander(f"ğŸ“– Ø£Ø­ÙƒØ§Ù… ÙƒÙ„Ù…Ø©: {word}"):
                        st.dataframe(pd.DataFrame(tajweed_data), use_container_width=True, hide_index=True)
            
            st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âš ï¸ ØªØ¹Ø°Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„: ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ±ØªÙŠÙ„ Ø¨ÙˆØ¶ÙˆØ­. (Ø§Ù„Ø³Ø¨Ø¨: {e})")
