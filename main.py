import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import librosa
import numpy as np
import re
from streamlit_mic_recorder import mic_recorder
from pydub import AudioSegment

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© ---
st.set_page_config(page_title="Ù…ØµØ­Ø­ ØªÙ„Ø§ÙˆØ© ÙˆØ±Ø´ Ø§Ù„Ø´Ø§Ù…Ù„", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { font-family: 'Amiri', serif; direction: rtl; text-align: right; }
    .quran-container {
        background-color: #fcfdfc; padding: 25px; border-radius: 15px;
        border-right: 10px solid #2E7D32; box-shadow: 0 4px 15px rgba(0,0,0,0.05);
    }
    .tajweed-tile { background-color: #ffffff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 10px; margin-top: 5px; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ù…Ù† CSV (ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©) ---
@st.cache_data
def load_rules():
    if os.path.exists('arabic_phonetics.csv'):
        return pd.read_csv('arabic_phonetics.csv', encoding='utf-8-sig')
    return None

df_rules = load_rules()

# --- 3. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠ ---

def get_tajweed_feedback(word):
    """Ø±Ø¨Ø· Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ù† Ù…Ù„Ù CSV (Ø§Ù„Ø­ÙƒÙ…ØŒ Ø§Ù„Ù…Ø®Ø±Ø¬ØŒ Ø§Ù„ØµÙØ©)"""
    feedback = []
    if df_rules is not None:
        clean_word = re.sub(r"[\u064B-\u0652]", "", word)
        for char in clean_word:
            match = df_rules[df_rules['letter'] == char]
            if not match.empty:
                row = match.iloc[0]
                feedback.append({
                    'Ø§Ù„Ø­Ø±Ù': row['letter'],
                    'Ø§Ù„Ø­ÙƒÙ…': row['rule_category'],
                    'Ø§Ù„Ù…Ø®Ø±Ø¬': row['place'],
                    'Ø§Ù„ØµÙØ©': row['emphasis']
                })
    return feedback

def analyze_audio_mad(audio_bytes):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ø§ÙƒØªØ´Ø§Ù Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ (6 Ø­Ø±ÙƒØ§Øª Ù„ÙˆØ±Ø´)"""
    audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
    buf = io.BytesIO()
    audio.export(buf, format="wav")
    buf.seek(0)
    y, sr_rate = librosa.load(buf)
    rms = librosa.feature.rms(y=y)[0]
    # Ø­Ø³Ø§Ø¨ Ø£Ø·ÙˆÙ„ Ø§Ø³ØªÙ…Ø±Ø§Ø± ØµÙˆØªÙŠ ÙÙˆÙ‚ Ø¹ØªØ¨Ø© Ù…Ø¹ÙŠÙ†Ø©
    threshold = np.max(rms) * 0.3
    durations = np.sum(rms > threshold) * (512 / sr_rate)
    return round(durations, 2), buf

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title("ğŸ•Œ Ù…ØµØ­Ø­ Ø§Ù„ØªÙ„Ø§ÙˆØ© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ (Ø±ÙˆØ§ÙŠØ© ÙˆØ±Ø´)")
st.write("ÙŠØªÙ… Ø§Ù„Ø¢Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø±Ø¬ ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©.")



with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¶Ø¨Ø·")
    target_text = st.text_area("Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", "Ø¥Ù†Ø§ Ø£Ø¹Ø·ÙŠÙ†Ø§Ùƒ Ø§Ù„ÙƒÙˆØ«Ø±")

audio_data = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ„Ø§ÙˆØ© Ø¨Ø§Ù„ØªØ±ØªÙŠÙ„", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø­ÙƒØ§Ù…", key='tajweed_checker')

if audio_data:
    audio_bytes = audio_data['bytes']
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬..."):
        try:
            # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ ÙˆØ§Ù„Ù„ÙØ¸ÙŠ
            mad_time, wav_buf = analyze_audio_mad(audio_bytes)
            
            r = sr.Recognizer()
            with sr.AudioFile(wav_buf) as source:
                r.adjust_for_ambient_noise(source)
                audio_recorded = r.record(source)
                spoken_text = r.recognize_google(audio_recorded, language="ar-SA")
            
            # Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            st.markdown("<div class='quran-container'>", unsafe_allow_html=True)
            st.subheader(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {spoken_text}")
            
            # ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬
            st.divider()
            st.markdown("### ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ø£Ø­ÙƒØ§Ù… Ø§Ù„ØªØ¬ÙˆÙŠØ¯ Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø©:")
            words = target_text.split()
            for word in words:
                tajweed_info = get_tajweed_feedback(word)
                with st.expander(f"ØªÙˆØ¬ÙŠÙ‡Ø§Øª ÙƒÙ„Ù…Ø©: {word}"):
                    if tajweed_info:
                        st.table(pd.DataFrame(tajweed_info))
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø¯ Ù„ÙˆØ±Ø´
            if mad_time < 3.0:
                st.warning(f"âš ï¸ Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ Ø§Ù„Ù…ÙƒØªØ´Ù ({mad_time} Ø«) Ù‚ØµÙŠØ±. ØªØ°ÙƒØ± Ø¥Ø´Ø¨Ø§Ø¹ Ø§Ù„Ù…Ø¯ Ù„Ù€ 6 Ø­Ø±ÙƒØ§Øª Ø¹Ù†Ø¯ ÙˆØ±Ø´.")
            else:
                st.success(f"âœ… Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ ({mad_time} Ø«) Ù…Ù…ØªØ§Ø² ÙˆÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ù‚.")
            
            st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error("ØªØ¹Ø°Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ±ØªÙŠÙ„ Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ«Ø¨Ø§Øª Ø£Ù…Ø§Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.")
