import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import librosa
import numpy as np
import re
from streamlit_mic_recorder import mic_recorder
from pydub import AudioSegment

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© ---
st.set_page_config(page_title="Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø°ÙƒÙŠØ©", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { font-family: 'Amiri', serif; direction: rtl; text-align: right; }
    .quran-box {
        background-color: #fcfdfc; padding: 25px; border-radius: 15px;
        border-right: 10px solid #2E7D32; box-shadow: 0 4px 10px rgba(0,0,0,0.05);
    }
    .metric-card { background-color: white; padding: 15px; border-radius: 12px; border: 1px solid #e0e0e0; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Ø§Ù„Ø®Ù„ÙÙŠØ©) ---
@st.cache_data
def load_rules():
    if os.path.exists('arabic_phonetics.csv'):
        return pd.read_csv('arabic_phonetics.csv', encoding='utf-8-sig')
    return None

df_rules = load_rules()

def normalize_arabic(text):
    """ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø­Ø±ÙˆÙ Ù„Ø²ÙŠØ§Ø¯Ø© Ø¯Ù‚Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©"""
    text = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", text)
    text = re.sub(r"[\u064B-\u0652]", "", text) # Ø­Ø°Ù Ø§Ù„ØªØ´ÙƒÙŠÙ„
    return text.strip()

def get_word_analysis(word):
    """Ø±Ø¨Ø· Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ Ù…Ù† Ù…Ù„Ù CSV"""
    analysis = []
    if df_rules is not None:
        clean_word = re.sub(r"[\u064B-\u0652]", "", word)
        for char in clean_word:
            match = df_rules[df_rules['letter'] == char]
            if not match.empty:
                row = match.iloc[0]
                analysis.append({
                    'Ø§Ù„Ø­Ø±Ù': row['letter'],
                    'Ø§Ù„Ù…Ø®Ø±Ø¬': row['place'],
                    'Ø§Ù„Ø­ÙƒÙ…': row['rule_category'],
                    'Ø§Ù„ØµÙØ©': row['emphasis']
                })
    return analysis

# --- 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title("ğŸ•Œ Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø©")
st.write("Ù†Ø¸Ø§Ù… ØªØµØ­ÙŠØ­ Ø§Ù„ØªÙ„Ø§ÙˆØ© ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù…")



with st.sidebar:
    st.header("ğŸ“– Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ­ÙŠØ­")
    target_text = st.text_area("Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØµØ­ÙŠØ­Ù‡Ø§:", "Ø¥Ù†Ø§ Ø£Ø¹Ø·ÙŠÙ†Ø§Ùƒ Ø§Ù„ÙƒÙˆØ«Ø±")
    st.info("ğŸ’¡ ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„Ù Ø§Ù„Ø£Ø­ÙƒØ§Ù… (CSV) Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø®Ø§Ø±Ø¬ Ø­Ø±ÙˆÙÙƒ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©.")

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
audio_data = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ„Ø§ÙˆØ©", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù ÙˆØ§Ø·Ù„Ø¨ Ø§Ù„ØªÙ‚Ø±ÙŠØ±", key='warsh_v9')

if audio_data:
    audio_bytes = audio_data['bytes']
    
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬..."):
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„ØµÙŠØºØ© WAV PCM Ù„Ø¶Ù…Ø§Ù† ÙÙ‡Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ Ù„Ù‡
            audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
            wav_buf = io.BytesIO()
            audio.export(wav_buf, format="wav")
            wav_buf.seek(0)
            
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…
            r = sr.Recognizer()
            with sr.AudioFile(wav_buf) as source:
                # ØªÙ‚Ù„ÙŠÙ„ Ø£Ø«Ø± Ø§Ù„Ø¶Ø¬ÙŠØ¬ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„
                r.adjust_for_ambient_noise(source, duration=0.5)
                audio_recorded = r.record(source)
                spoken_text = r.recognize_google(audio_recorded, language="ar-SA")
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù„ÙØ¸ÙŠØ©
            norm_target = normalize_arabic(target_text)
            norm_spoken = normalize_arabic(spoken_text)
            accuracy = round(difflib.SequenceMatcher(None, norm_target.split(), norm_spoken.split()).ratio() * 100, 1)

            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.markdown("<div class='quran-box'>", unsafe_allow_html=True)
            st.metric("Ù†Ø³Ø¨Ø© Ø¥ØªÙ‚Ø§Ù† Ø§Ù„Ù…Ø®Ø§Ø±Ø¬", f"{accuracy}%")
            st.write(f"**Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªØ´Ù:** {spoken_text}")
            
            # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ø£Ø­ÙƒØ§Ù…
            st.subheader("ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù… (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„ÙÙƒ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ):")
            words = target_text.split()
            for word in words:
                tajweed_info = get_word_analysis(word)
                if tajweed_info:
                    with st.expander(f"ØªÙØ§ØµÙŠÙ„ ÙƒÙ„Ù…Ø©: {word}"):
                        st.table(pd.DataFrame(tajweed_info))
            
            if accuracy > 85:
                st.success("Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡! ØªÙ„Ø§ÙˆØ© ØµØ­ÙŠØ­Ø©.")
                st.balloons()
            else:
                st.error("ÙŠÙˆØ¬Ø¯ Ø§Ø®ØªÙ„Ø§Ù ÙÙŠ Ù†Ø·Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø£Ø¹Ù„Ø§Ù‡.")
            st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª. Ø­Ø§ÙˆÙ„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø¨ÙˆØ¶ÙˆØ­ Ø£ÙƒØ¨Ø± Ø£Ùˆ ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.")
