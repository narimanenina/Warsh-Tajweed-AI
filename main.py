import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import re
import time
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import random
import datetime
from streamlit_mic_recorder import mic_recorder
from pydub import AudioSegment
from fpdf import FPDF

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© ---
st.set_page_config(page_title="Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø°ÙƒÙŠØ©", layout="wide", page_icon="ğŸ•Œ")

if 'history' not in st.session_state: st.session_state.history = []
if 'error_tracker' not in st.session_state: st.session_state.error_tracker = {}
if 'high_scores' not in st.session_state: st.session_state.high_scores = {}
if 'daily_seed' not in st.session_state: st.session_state.daily_seed = datetime.date.today().strftime("%Y%m%d")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { font-family: 'Amiri', serif; direction: rtl; text-align: center; }
    .quran-container {
        background-color: #ffffff; padding: 35px; border-radius: 25px;
        border: 2px solid #2E7D32; margin: 20px auto; max-width: 950px;
        display: flex; flex-wrap: wrap; justify-content: center; gap: 15px;
    }
    .word-correct { color: #2E7D32; font-size: 38px; font-weight: bold; }
    .word-error { color: #D32F2F; font-size: 38px; font-weight: bold; text-decoration: underline; }
    .word-pending { color: #444444; font-size: 38px; }
    .challenge-box { background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%); padding: 20px; border-radius: 15px; border-right: 8px solid #2E7D32; margin-bottom: 25px; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ---
surahs = {
    "Ø³ÙˆØ±Ø© Ø§Ù„ÙƒÙˆØ«Ø±": "Ø¥ÙÙ†Ù‘ÙØ§ Ø£ÙØ¹Ù’Ø·ÙÙŠÙ’Ù†ÙØ§ÙƒÙ Ø§Ù„Ù’ÙƒÙÙˆÙ’Ø«ÙØ±Ù ÙÙØµÙÙ„Ù‘Ù Ù„ÙØ±ÙØ¨Ù‘ÙÙƒÙ ÙˆÙØ§Ù†Ù’Ø­ÙØ±Ù’ Ø¥ÙÙ†Ù‘Ù Ø´ÙØ§Ù†ÙØ¦ÙÙƒÙ Ù‡ÙÙˆÙ Ø§Ù„Ù’Ø£ÙØ¨Ù’ØªÙØ±Ù",
    "Ø³ÙˆØ±Ø© Ø§Ù„Ø¥Ø®Ù„Ø§Øµ": "Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙ Ø§Ù„Ù„Ù‘ÙÙ‡Ù Ø£ÙØ­ÙØ¯ÙŒ Ø§Ù„Ù„Ù‘ÙÙ‡Ù Ø§Ù„ØµÙ‘ÙÙ…ÙØ¯Ù Ù„ÙÙ…Ù’ ÙŠÙÙ„ÙØ¯Ù’ ÙˆÙÙ„ÙÙ…Ù’ ÙŠÙÙˆÙ„ÙØ¯Ù’ ÙˆÙÙ„ÙÙ…Ù’ ÙŠÙÙƒÙÙ† Ù„Ù‘ÙÙ‡Ù ÙƒÙÙÙÙˆÙ‹Ø§ Ø£ÙØ­ÙØ¯ÙŒ",
    "Ø³ÙˆØ±Ø© Ø§Ù„ÙØ§ØªØ­Ø©": "Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯Ù Ù„ÙÙ„Ù‘ÙÙ‡Ù Ø±ÙØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù Ø§Ù„Ø±Ù‘ÙØ­Ù’Ù…ÙÙ†Ù Ø§Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù Ù…ÙØ§Ù„ÙÙƒÙ ÙŠÙÙˆÙ’Ù…Ù Ø§Ù„Ø¯Ù‘ÙÙŠÙ†Ù Ø¥ÙÙŠÙ‘ÙØ§ÙƒÙ Ù†ÙØ¹Ù’Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙ‘ÙØ§ÙƒÙ Ù†ÙØ³Ù’ØªÙØ¹ÙÙŠÙ†Ù Ø§Ù‡Ù’Ø¯ÙŠÙ†Ø§ Ø§Ù„ØµÙ‘ÙØ±ÙØ§Ø·Ù Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙÙ‚ÙÙŠÙ…Ù ØµÙØ±ÙØ§Ø·Ù Ø§Ù„Ù‘ÙØ°ÙÙŠÙ†Ù Ø£ÙÙ†Ù’Ø¹ÙÙ…Ù’ØªÙ Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ØºÙÙŠÙ’Ø±Ù Ø§Ù„Ù’Ù…ÙØºÙ’Ø¶ÙÙˆØ¨Ù Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ÙˆÙÙ„ÙØ§ Ø§Ù„Ø¶Ù‘ÙØ§Ù„Ù‘ÙÙŠÙ†Ù"
}

@st.cache_data
def load_phonetics():
    try: return pd.read_csv('arabic_phonetics.csv')
    except: return None

def clean_text(text): return re.sub(r"[\u064B-\u0652]", "", text).strip()

def generate_cert(user_name, surah, acc):
    pdf = FPDF(orientation='L', unit='mm', format='A4')
    pdf.add_page()
    pdf.rect(10, 10, 277, 190)
    pdf.set_font("Arial", 'B', 30)
    pdf.cell(0, 50, "Certificate of Recitation Mastery", ln=True, align='C')
    pdf.set_font("Arial", '', 20)
    pdf.cell(0, 20, f"This certifies that {user_name}", ln=True, align='C')
    pdf.cell(0, 20, f"Mastered {surah} with {acc}% Accuracy", ln=True, align='C')
    pdf.cell(0, 30, f"Date: {datetime.date.today()}", ln=True, align='C')
    return pdf.output(dest='S')

# --- 3. ØªØµÙ…ÙŠÙ… ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª ---
st.title("ğŸ•Œ Ù…Ù†ØµØ© ÙˆØ±Ø´ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©")
tab1, tab2, tab3 = st.tabs(["ğŸ¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„ØªØ­Ø¯ÙŠ", "ğŸ”¬ Ø§Ù„Ù…Ø®ØªØ¨Ø± Ø§Ù„ØªØ±Ø¯Ø¯ÙŠ", "ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"])

with tab1:
    # ØªØ­Ø¯ÙŠ Ø§Ù„ÙŠÙˆÙ…
    random.seed(st.session_state.daily_seed)
    daily_s = random.choice(list(surahs.keys()))
    st.markdown(f"<div class='challenge-box'><h3>ğŸ¯ ØªØ­Ø¯ÙŠ Ø§Ù„ÙŠÙˆÙ…: {daily_s}</h3></div>", unsafe_allow_html=True)
    
    selected_s = st.selectbox("Ø§Ø®ØªØ± Ø³ÙˆØ±Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±:", list(surahs.keys()))
    target_v = surahs[selected_s]
    target_w = target_v.split()
    
    placeholder = st.empty()
    placeholder.markdown(f"<div class='quran-container'>{' '.join([f'<span class=word-pending>{w}</span>' for w in target_w])}</div>", unsafe_allow_html=True)
    
    audio = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ±ØªÙŠÙ„", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù Ù„Ù„ØªØ­Ù„ÙŠÙ„", key='main_recorder')

    if audio:
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ ØªÙ„Ø§ÙˆØªÙƒ..."):
            try:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
                raw_audio = AudioSegment.from_file(io.BytesIO(audio['bytes']))
                duration = len(raw_audio) / 1000.0
                r = sr.Recognizer()
                with sr.AudioFile(io.BytesIO(audio['bytes'])) as source:
                    spoken = r.recognize_google(r.record(source), language="ar-SA")
                
                spoken_w = [clean_text(w) for w in spoken.split()]
                
                # Ø¹Ø±Ø¶ Ù…Ù„ÙˆÙ† ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
                res_html = "<div class='quran-container'>"
                correct = 0
                for w in target_w:
                    if clean_text(w) in spoken_w:
                        res_html += f"<span class='word-correct'>{w}</span> "
                        correct += 1
                    else:
                        res_html += f"<span class='word-error'>{w}</span> "
                res_html += "</div>"
                placeholder.markdown(res_html, unsafe_allow_html=True)
                
                acc = (correct / len(target_w)) * 100
                wpm = (correct / duration) * 60 if duration > 0 else 0
                
                # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                c1, c2, c3 = st.columns(3)
                c1.metric("ğŸ¯ Ø§Ù„Ø¯Ù‚Ø©", f"{round(acc)}%")
                c2.metric("â±ï¸ Ø§Ù„Ø²Ù…Ù†", f"{round(duration, 1)} Ø«")
                c3.metric("ğŸš€ Ø§Ù„Ø·Ù„Ø§Ù‚Ø©", f"{round(wpm)} ÙƒÙ„Ù…Ø©/Ø¯")
                
                # Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„
                st.session_state.history.append({"Ø³ÙˆØ±Ø©": selected_s, "Ø¯Ù‚Ø©": acc, "Ø³Ø±Ø¹Ø©": wpm})
                
                # Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©
                if acc >= 90:
                    st.success("ğŸ† Ø¥ØªÙ‚Ø§Ù† Ù…Ø°Ù‡Ù„!")
                    u_name = st.text_input("Ø§Ø³Ù…Ùƒ Ù„Ù„Ø´Ù‡Ø§Ø¯Ø©:", "Ù‡Ø§Ù†ÙŠ Ù…Ø¹Ù…Ø±ÙŠ")
                    if st.button("ğŸ“„ Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©"):
                        pdf_data = generate_cert(u_name, selected_s, round(acc))
                        st.download_button("ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©", pdf_data, f"Cert_{selected_s}.pdf", "application/pdf")

            except: st.error("ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨ØµÙˆØª Ø£ÙˆØ¶Ø­.")

with tab2:
    st.subheader("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ù…Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ (Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª)")
    test_char = st.selectbox("Ø§Ø®ØªØ± Ø­Ø±ÙØ§Ù‹ Ù„Ù„ØªØ­Ù„ÙŠÙ„:", ["Ù‚", "Ø¯", "Ø³", "Ø±"])
    q_audio = mic_recorder(start_prompt=f"Ø§Ù†Ø·Ù‚ Ø­Ø±Ù ({test_char})", stop_prompt="ØªØ­Ù„ÙŠÙ„", key='q_mic')
    if q_audio:
        y, sr_rate = librosa.load(io.BytesIO(q_audio['bytes']), sr=22050)
        fig, ax = plt.subplots()
        S = librosa.feature.melspectrogram(y=y, sr=sr_rate)
        librosa.display.specshow(librosa.power_to_db(S, ref=np.max), ax=ax, y_axis='mel', x_axis='time')
        st.pyplot(fig)
        st.info(f"ÙŠÙØ¸Ù‡Ø± Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª Ù„Ø­Ø±Ù {test_char}. Ø§Ø¨Ø­Ø« Ø¹Ù† Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø§Ù„Ø·Ø§Ù‚ÙŠ.")
        

with tab3:
    st.subheader("ğŸ“ˆ Ø³Ø¬Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡")
    if st.session_state.history:
        df_hist = pd.DataFrame(st.session_state.history)
        st.line_chart(df_hist['Ø¯Ù‚Ø©'])
        st.table(df_hist)
    else: st.write("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª.")
