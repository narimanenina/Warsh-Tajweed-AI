import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import librosa
import numpy as np
import soundfile as sf
from streamlit_mic_recorder import mic_recorder
from pydub import AudioSegment

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ---
st.set_page_config(page_title="Ù…ØµØ­Ø­ ØªÙ„Ø§ÙˆØ© ÙˆØ±Ø´ - Ù†Ø³Ø®Ø© Ù…Ø³ØªÙ‚Ø±Ø©", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { font-family: 'Amiri', serif; direction: rtl; text-align: right; }
    .main-box { background-color: #f4f9f4; padding: 25px; border-radius: 15px; border-right: 10px solid #1B5E20; }
    .metric-card { background-color: white; padding: 15px; border-radius: 10px; border: 1px solid #c8e6c9; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙŠØº ---
def process_audio_data(audio_bytes):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª Ø§Ù„Ù…Ø³Ø¬Ù„Ø© Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ Ø¥Ù„Ù‰ ØµÙŠØºØ© WAV PCM ØµØ§Ù„Ø­Ø©"""
    audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ Mono ÙˆØªØ±Ø¯Ø¯ 16000Hz Ù„Ø¶Ù…Ø§Ù† Ø£ÙØ¶Ù„ Ø¯Ù‚Ø© Ù…Ø¹ Ø¬ÙˆØ¬Ù„ ÙˆÙ„ÙŠØ¨Ø±ÙˆØ³Ø§
    audio_segment = audio_segment.set_channels(1).set_frame_rate(16000)
    
    buf = io.BytesIO()
    audio_segment.export(buf, format="wav")
    buf.seek(0)
    return buf

# --- 3. Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ù…Ø¯ ÙˆØ±Ø´ (Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ù‚) ---
def analyze_warsh_duration(wav_buf):
    y, sr_rate = librosa.load(wav_buf)
    rms = librosa.feature.rms(y=y)[0]
    smoothed_rms = np.convolve(rms, np.ones(5)/5, mode='same')
    is_speech = smoothed_rms > (np.max(smoothed_rms) * 0.25)
    
    durations = []
    count = 0
    for s in is_speech:
        if s: count += 1
        else:
            if count > 0: durations.append(count * (512 / sr_rate))
            count = 0
    return round(max(durations), 2) if durations else 0

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.title("ğŸ•Œ Ù…ØµØ­Ø­ ØªÙ„Ø§ÙˆØ© ÙˆØ±Ø´ Ø§Ù„Ø°ÙƒÙŠ")

with st.sidebar:
    st.header("ğŸ‘¤ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ø±Ø¦")
    surahs = {"Ø³ÙˆØ±Ø© Ø§Ù„ÙƒÙˆØ«Ø±": "Ø¥Ù†Ø§ Ø£Ø¹Ø·ÙŠÙ†Ø§Ùƒ Ø§Ù„ÙƒÙˆØ«Ø±", "Ø³ÙˆØ±Ø© Ø§Ù„ÙØ§ØªØ­Ø©": "ØºÙŠØ± Ø§Ù„Ù…ØºØ¶ÙˆØ¨ Ø¹Ù„ÙŠÙ‡Ù… ÙˆÙ„Ø§ Ø§Ù„Ø¶Ø§Ù„ÙŠÙ†"}
    choice = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙˆØ±Ø©:", list(surahs.keys()))
    target_text = surahs[choice]
    st.info(f"Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©: {target_text}")

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
audio_record = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ„Ø§ÙˆØ©", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù ÙˆØ§Ø·Ù„Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø©", key='final_rec')

if audio_record:
    audio_bytes = audio_record['bytes']
    
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¬ÙˆÙŠØ¯..."):
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙŠØºØ© (Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© PCM WAV)
            wav_buffer = process_audio_data(audio_bytes)
            
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ
            r = sr.Recognizer()
            with sr.AudioFile(wav_buffer) as source:
                audio_data = r.record(source)
                spoken_text = r.recognize_google(audio_data, language="ar-SA")
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯
            wav_buffer.seek(0) # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø´Ø± Ù„Ù„Ø¨Ø¯Ø§ÙŠØ©
            mad_time = analyze_warsh_duration(wav_buffer)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
            acc = round(difflib.SequenceMatcher(None, target_text.split(), spoken_text.split()).ratio() * 100, 1)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.markdown("<div class='main-box'>", unsafe_allow_html=True)
            c1, c2 = st.columns(2)
            c1.markdown(f"<div class='metric-card'><h4>ØµØ­Ø© Ø§Ù„Ù„ÙØ¸</h4><h2>{acc}%</h2></div>", unsafe_allow_html=True)
            c2.markdown(f"<div class='metric-card'><h4>Ø£Ø·ÙˆÙ„ Ù…Ø¯</h4><h2>{mad_time} Ø«</h2></div>", unsafe_allow_html=True)
            
            st.write(f"**Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚:** {spoken_text}")
            
            if acc > 85 and mad_time >= 3.5:
                st.success("Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡! ØªÙ„Ø§ÙˆØ© ØµØ­ÙŠØ­Ø© Ù…Ø¹ Ù…Ø¯ Ù…Ø´Ø¨Ø¹ (Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ù‚).")
            elif acc > 85:
                st.warning("Ø§Ù„Ù„ÙØ¸ ØµØ­ÙŠØ­ ÙˆÙ„ÙƒÙ† Ø§Ù„Ù…Ø¯ Ù‚ØµÙŠØ± (ÙˆØ±Ø´ ÙŠÙ…Ø¯ 6 Ø­Ø±ÙƒØ§Øª).")
            else:
                st.error("ÙŠÙˆØ¬Ø¯ Ø®Ø·Ø£ ÙÙŠ Ù†Ø·Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§Øª.")
            st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âš ï¸ Ø®Ø·Ø£ ÙÙ†ÙŠ: ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ù… Ø¨ÙˆØ¶ÙˆØ­ (Ø§Ù„ØªÙØ§ØµÙŠÙ„: {str(e)})")
