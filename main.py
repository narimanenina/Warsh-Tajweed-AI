import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import librosa
import numpy as np
import soundfile as sf
import re
from streamlit_mic_recorder import mic_recorder

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª (Ù…Ø¹ Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„) ---
st.set_page_config(page_title="Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø°ÙƒÙŠØ©", layout="centered", page_icon="ğŸ•Œ")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { 
        font-family: 'Amiri', serif; 
        direction: rtl; 
        text-align: right; 
    }
    /* ØªØ­Ø³ÙŠÙ† Ø´ÙƒÙ„ Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª ÙˆÙ…Ù†Ø¹ ØªØ¯Ø§Ø®Ù„ Ø§Ù„Ù†ØµÙˆØµ Ù…Ø¹ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª */
    .st-emotion-cache-p4m61c { 
        flex-direction: row-reverse !important; 
    }
    .quran-container {
        background-color: #fcfdfc; padding: 25px; border-radius: 15px;
        border-right: 10px solid #2E7D32; box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        margin-bottom: 20px;
    }
    .stButton>button { 
        background-color: #2E7D32; color: white; border-radius: 10px; 
        width: 100%; height: 3.5em; font-size: 18px;
    }
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© */
    .stDataFrame { margin-top: 10px; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© ---
@st.cache_data
def load_rules():
    if os.path.exists('arabic_phonetics.csv'):
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: letter, name, place, rule_category, emphasis, ipa
        return pd.read_csv('arabic_phonetics.csv', encoding='utf-8-sig')
    return None

df_rules = load_rules()

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„ØªØµØ­ÙŠØ­ ---

def get_tajweed_analysis(word):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬ÙˆÙŠØ¯ Ù„ÙƒÙ„ Ø­Ø±Ù ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ù† Ù…Ù„Ù CSV"""
    analysis = []
    if df_rules is not None:
        clean_word = re.sub(r"[\u064B-\u0652]", "", word)
        for char in clean_word:
            match = df_rules[df_rules['letter'] == char]
            if not match.empty:
                row = match.iloc[0]
                analysis.append({
                    'Ø§Ù„Ø­Ø±Ù': row['letter'],
                    'Ø§Ù„Ù…Ø®Ø±Ø¬': row['place'],
                    'Ø§Ù„Ø­ÙƒÙ…': row['rule_category'],
                    'Ø§Ù„ØµÙØ©': row['emphasis']
                })
    return analysis

def process_audio_raw(audio_bytes):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ø®Ø§Ù… ÙˆØ­Ø³Ø§Ø¨ Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚"""
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©
    with io.BytesIO(audio_bytes) as audio_file:
        data, samplerate = sf.read(audio_file)
    
    if len(data.shape) > 1: data = np.mean(data, axis=1) # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ Mono
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯ (6 Ø­Ø±ÙƒØ§Øª Ù„ÙˆØ±Ø´)
    rms = librosa.feature.rms(y=data)[0]
    threshold = np.max(rms) * 0.25
    mad_duration = np.sum(rms > threshold) * (512 / samplerate)
    
    # ØªØµØ¯ÙŠØ± Ù„Ù…Ù„Ù WAV Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    buf = io.BytesIO()
    sf.write(buf, data, samplerate, format='WAV', subtype='PCM_16')
    buf.seek(0)
    return round(mad_duration, 2), buf

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.markdown("<h1 style='text-align: center; color: #1B5E20;'>ğŸ•Œ Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©</h1>", unsafe_allow_html=True)
st.write("<p style='text-align: center;'>ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</p>", unsafe_allow_html=True)

with st.sidebar:
    st.header("ğŸ“– Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØµØ­Ø­")
    target_text = st.text_area("Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", "Ø¥Ù†Ø§ Ø£Ø¹Ø·ÙŠÙ†Ø§Ùƒ Ø§Ù„ÙƒÙˆØ«Ø±")
    st.info("ğŸ’¡ ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø© ØªÙ†Ø·Ù‚Ù‡Ø§ ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ø£Ø­ÙƒØ§Ù… Ø§Ù„ØªØ¬ÙˆÙŠØ¯ ÙÙŠ Ù…Ù„ÙÙƒ Ø§Ù„Ø®Ø§Øµ.")

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
audio_record = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ„Ø§ÙˆØ© Ø¨Ø§Ù„ØªØ±ØªÙŠÙ„", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù ÙˆØ§Ø·Ù„Ø¨ Ø§Ù„ØªØµØ­ÙŠØ­", key='warsh_v12')

if audio_record:
    audio_bytes = audio_record['bytes']
    
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¬ÙˆÙŠØ¯ÙŠ..."):
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯
            mad_time, wav_buffer = process_audio_raw(audio_bytes)
            
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ
            r = sr.Recognizer()
            with sr.AudioFile(wav_buffer) as source:
                r.adjust_for_ambient_noise(source)
                audio_recorded = r.record(source)
                spoken_text = r.recognize_google(audio_recorded, language="ar-SA")
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù„ÙØ¸ÙŠØ©
            norm_target = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", target_text)
            norm_spoken = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", spoken_text)
            accuracy = round(difflib.SequenceMatcher(None, norm_target.split(), norm_spoken.split()).ratio() * 100, 1)

            # --- Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ---
            st.markdown("<div class='quran-container'>", unsafe_allow_html=True)
            st.subheader(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {accuracy}%")
            st.write(f"**Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚:** {spoken_text}")
            
            st.divider()
            st.markdown("### ğŸ“‹ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„ÙÙƒ):")
            
            words = target_text.split()
            for word in words:
                tajweed_info = get_tajweed_analysis(word)
                if tajweed_info:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… expander Ù…Ø¹ Ø¬Ø¯ÙˆÙ„ Ù…Ù†Ø³Ù‚ ÙŠÙ…Ù†Ø¹ ØªØ¯Ø§Ø®Ù„ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª
                    with st.expander(f"ğŸ“– Ø£Ø­ÙƒØ§Ù… ÙƒÙ„Ù…Ø©: {word}"):
                        st.dataframe(
                            pd.DataFrame(tajweed_info),
                            use_container_width=True,
                            hide_index=True
                        )
            
            # ØªÙ‚ÙŠÙŠÙ… Ø²Ù…Ù† Ø§Ù„Ù…Ø¯
            if mad_time < 3.0:
                st.warning(f"âš ï¸ Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ ({mad_time} Ø«) Ù‚ØµÙŠØ±. ØªØ°ÙƒØ± Ø¥Ø´Ø¨Ø§Ø¹ Ø§Ù„Ù…Ø¯ Ù„Ù€ 6 Ø­Ø±ÙƒØ§Øª ÙÙŠ Ø±ÙˆØ§ÙŠØ© ÙˆØ±Ø´.")
            else:
                st.success(f"âœ… Ø¥ØªÙ‚Ø§Ù† Ù…Ù…ØªØ§Ø²! Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ ({mad_time} Ø«) ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ù‚.")
            
            st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âš ï¸ ØªØ¹Ø°Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„: ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ±ØªÙŠÙ„ Ø¨ÙˆØ¶ÙˆØ­. (Ø§Ù„Ø³Ø¨Ø¨: {e})")import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import librosa
import numpy as np
import soundfile as sf
import re
from streamlit_mic_recorder import mic_recorder

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª (Ù…Ø¹ Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„) ---
st.set_page_config(page_title="Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø°ÙƒÙŠØ©", layout="centered", page_icon="ğŸ•Œ")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri&display=swap');
    html, body, [class*="st-"] { 
        font-family: 'Amiri', serif; 
        direction: rtl; 
        text-align: right; 
    }
    /* ØªØ­Ø³ÙŠÙ† Ø´ÙƒÙ„ Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª ÙˆÙ…Ù†Ø¹ ØªØ¯Ø§Ø®Ù„ Ø§Ù„Ù†ØµÙˆØµ Ù…Ø¹ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª */
    .st-emotion-cache-p4m61c { 
        flex-direction: row-reverse !important; 
    }
    .quran-container {
        background-color: #fcfdfc; padding: 25px; border-radius: 15px;
        border-right: 10px solid #2E7D32; box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        margin-bottom: 20px;
    }
    .stButton>button { 
        background-color: #2E7D32; color: white; border-radius: 10px; 
        width: 100%; height: 3.5em; font-size: 18px;
    }
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© */
    .stDataFrame { margin-top: 10px; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© ---
@st.cache_data
def load_rules():
    if os.path.exists('arabic_phonetics.csv'):
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: letter, name, place, rule_category, emphasis, ipa
        return pd.read_csv('arabic_phonetics.csv', encoding='utf-8-sig')
    return None

df_rules = load_rules()

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„ØªØµØ­ÙŠØ­ ---

def get_tajweed_analysis(word):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬ÙˆÙŠØ¯ Ù„ÙƒÙ„ Ø­Ø±Ù ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ù† Ù…Ù„Ù CSV"""
    analysis = []
    if df_rules is not None:
        clean_word = re.sub(r"[\u064B-\u0652]", "", word)
        for char in clean_word:
            match = df_rules[df_rules['letter'] == char]
            if not match.empty:
                row = match.iloc[0]
                analysis.append({
                    'Ø§Ù„Ø­Ø±Ù': row['letter'],
                    'Ø§Ù„Ù…Ø®Ø±Ø¬': row['place'],
                    'Ø§Ù„Ø­ÙƒÙ…': row['rule_category'],
                    'Ø§Ù„ØµÙØ©': row['emphasis']
                })
    return analysis

def process_audio_raw(audio_bytes):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ø®Ø§Ù… ÙˆØ­Ø³Ø§Ø¨ Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚"""
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©
    with io.BytesIO(audio_bytes) as audio_file:
        data, samplerate = sf.read(audio_file)
    
    if len(data.shape) > 1: data = np.mean(data, axis=1) # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ Mono
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯ (6 Ø­Ø±ÙƒØ§Øª Ù„ÙˆØ±Ø´)
    rms = librosa.feature.rms(y=data)[0]
    threshold = np.max(rms) * 0.25
    mad_duration = np.sum(rms > threshold) * (512 / samplerate)
    
    # ØªØµØ¯ÙŠØ± Ù„Ù…Ù„Ù WAV Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    buf = io.BytesIO()
    sf.write(buf, data, samplerate, format='WAV', subtype='PCM_16')
    buf.seek(0)
    return round(mad_duration, 2), buf

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.markdown("<h1 style='text-align: center; color: #1B5E20;'>ğŸ•Œ Ù…Ù‚Ø±Ø£Ø© ÙˆØ±Ø´ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©</h1>", unsafe_allow_html=True)
st.write("<p style='text-align: center;'>ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</p>", unsafe_allow_html=True)

with st.sidebar:
    st.header("ğŸ“– Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØµØ­Ø­")
    target_text = st.text_area("Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", "Ø¥Ù†Ø§ Ø£Ø¹Ø·ÙŠÙ†Ø§Ùƒ Ø§Ù„ÙƒÙˆØ«Ø±")
    st.info("ğŸ’¡ ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø© ØªÙ†Ø·Ù‚Ù‡Ø§ ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ø£Ø­ÙƒØ§Ù… Ø§Ù„ØªØ¬ÙˆÙŠØ¯ ÙÙŠ Ù…Ù„ÙÙƒ Ø§Ù„Ø®Ø§Øµ.")

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
audio_record = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ„Ø§ÙˆØ© Ø¨Ø§Ù„ØªØ±ØªÙŠÙ„", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù ÙˆØ§Ø·Ù„Ø¨ Ø§Ù„ØªØµØ­ÙŠØ­", key='warsh_v12')

if audio_record:
    audio_bytes = audio_record['bytes']
    
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¬ÙˆÙŠØ¯ÙŠ..."):
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯
            mad_time, wav_buffer = process_audio_raw(audio_bytes)
            
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ
            r = sr.Recognizer()
            with sr.AudioFile(wav_buffer) as source:
                r.adjust_for_ambient_noise(source)
                audio_recorded = r.record(source)
                spoken_text = r.recognize_google(audio_recorded, language="ar-SA")
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù„ÙØ¸ÙŠØ©
            norm_target = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", target_text)
            norm_spoken = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", spoken_text)
            accuracy = round(difflib.SequenceMatcher(None, norm_target.split(), norm_spoken.split()).ratio() * 100, 1)

            # --- Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ---
            st.markdown("<div class='quran-container'>", unsafe_allow_html=True)
            st.subheader(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {accuracy}%")
            st.write(f"**Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚:** {spoken_text}")
            
            st.divider()
            st.markdown("### ğŸ“‹ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù…Ø®Ø§Ø±Ø¬ (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„ÙÙƒ):")
            
            words = target_text.split()
            for word in words:
                tajweed_info = get_tajweed_analysis(word)
                if tajweed_info:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… expander Ù…Ø¹ Ø¬Ø¯ÙˆÙ„ Ù…Ù†Ø³Ù‚ ÙŠÙ…Ù†Ø¹ ØªØ¯Ø§Ø®Ù„ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª
                    with st.expander(f"ğŸ“– Ø£Ø­ÙƒØ§Ù… ÙƒÙ„Ù…Ø©: {word}"):
                        st.dataframe(
                            pd.DataFrame(tajweed_info),
                            use_container_width=True,
                            hide_index=True
                        )
            
            # ØªÙ‚ÙŠÙŠÙ… Ø²Ù…Ù† Ø§Ù„Ù…Ø¯
            if mad_time < 3.0:
                st.warning(f"âš ï¸ Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ ({mad_time} Ø«) Ù‚ØµÙŠØ±. ØªØ°ÙƒØ± Ø¥Ø´Ø¨Ø§Ø¹ Ø§Ù„Ù…Ø¯ Ù„Ù€ 6 Ø­Ø±ÙƒØ§Øª ÙÙŠ Ø±ÙˆØ§ÙŠØ© ÙˆØ±Ø´.")
            else:
                st.success(f"âœ… Ø¥ØªÙ‚Ø§Ù† Ù…Ù…ØªØ§Ø²! Ø²Ù…Ù† Ø§Ù„Ù…Ø¯ ({mad_time} Ø«) ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ù‚.")
            
            st.markdown("</div>", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âš ï¸ ØªØ¹Ø°Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„: ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ±ØªÙŠÙ„ Ø¨ÙˆØ¶ÙˆØ­. (Ø§Ù„Ø³Ø¨Ø¨: {e})")
